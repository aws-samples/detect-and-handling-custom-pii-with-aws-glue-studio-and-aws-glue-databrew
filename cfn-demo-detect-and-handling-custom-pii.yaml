# Copyright Amazon.com, Inc. or its affiliates. All Rights Reserved.
# SPDX-License-Identifier: MIT-0

---
AWSTemplateFormatVersion: '2010-09-09'
Description: 'Sample solution to automatically detect sensitive data in CSV files uploaded to S3 using Glue Sensitive Data Detection feature and hashing the columns by Glue Databrew with a secret.'

Parameters:
  SecretString:
    Type: String
    Description: Enter a secret string that will be used to hashing sensitive data
  1CustomSensitiveDataName:
    Type: String
    Description: Enter a unique custom pattern name for the 1st parameter.
    Default: demo_CEP
  1CustomSensitiveDataValue:
    Type: String
    Description: Enter a regular expression for the 1st parameter.
    Default: (^[0-9]{5})-?([0-9]{3}$)
  2CustomSensitiveDataName:
    Type: String
    Description: Enter a unique custom pattern name for the 2nd parameter.
    Default: demo_CNPJ
  2CustomSensitiveDataValue:
    Type: String
    Description: Enter a regular expression for the 2nd parameter.
    Default: (^\d{2}\.\d{3}\.\d{3}\/\d{4}\-\d{2}$)
  3CustomSensitiveDataName:
    Type: String
    Description: Enter a unique custom pattern name for the 3th parameter.
    Default: demo_CPF
  3CustomSensitiveDataValue:
    Type: String
    Description: Enter a regular expression for the 3th parameter.
    Default: (^\d{3}\.\d{3}\.\d{3}\-\d{2}$)
  4CustomSensitiveDataName:
    Type: String
    Description: Enter a unique custom pattern name for the 4th parameter.
    Default: demo_Telefone
  4CustomSensitiveDataValue:
    Type: String
    Description: Enter a regular expression for the 4th parameter.
    Default: (\(?\d{2}\)?\s?)?(9?\d{4}\-?\d{4})
  5CustomSensitiveDataName:
    Type: String
    Description: Enter a unique custom pattern name for the 5th parameter.
    Default: demo_RG
  5CustomSensitiveDataValue:
    Type: String
    Description: Enter a regular expression for the 5th parameter.
    Default: (^\d{1,2}).?(\d{3}).?(\d{3,4})(-\d{1}|X|x$)

Resources:
  # Step functions state machine
  StateMachineSensitiveDataTask:
    Type: 'AWS::StepFunctions::StateMachine'
    DependsOn: RoleStepFunctionsSensitiveDataTask
    Properties:
      StateMachineName: !Sub "${AWS::StackName}-StateMachineSensitiveDataTask"
      DefinitionString:
        !Sub
          - |-
            {
              "Comment": "Automatically detect Sensitive Data columns of data files loaded into S3, if detected columns will be ecrypted using hashing.",
              "StartAt": "Execute Glue Job to detect Sensitive Data",
              "States": {
                "Execute Glue Job to detect Sensitive Data": {
                  "Type": "Task",
                  "Resource": "arn:aws:states:::glue:startJobRun.sync",
                  "Parameters": {
                    "JobName": "${GlueJobSensitiveDatadetection}",
                    "Arguments": {
                      "--RANDOM.$": "$.id",
                      "--BUCKET_SOURCE.$": "$.detail.bucket.name",
                      "--KEY_SOURCE.$": "$.detail.object.key",
                      "--BUCKET_DEST": "${GlueDataBrewOutputBucketName}"
                    }
                  },
                  "Next": "Lambda Invoke",
                  "InputPath": "$",
                  "ResultPath": "$.GlueJobResult"
                  "Retry": [
                    {
                      "ErrorEquals": [
                        "States.ALL"
                      ],
                      "IntervalSeconds": 60,
                      "MaxAttempts": 3,
                      "BackoffRate": 30
                    }
                  ]
                },
                "Lambda Invoke": {
                  "Type": "Task",
                  "Resource": "arn:aws:states:::lambda:invoke",
                  "Parameters": {
                    "Payload": {
                      "bucket_dest": "${GlueDataBrewOutputBucketName}",
                      "path.$": "$.id"
                    },
                    "FunctionName": "${FunctionGlueDataBrewProfileReader.Arn}"
                  },
                  "Retry": [
                    {
                      "ErrorEquals": [
                        "Lambda.ServiceException",
                        "Lambda.AWSLambdaException",
                        "Lambda.SdkClientException"
                      ],
                      "IntervalSeconds": 2,
                      "MaxAttempts": 6,
                      "BackoffRate": 2
                    }
                  ],
                  "Next": "Validate if the Dataset Contains Sensitive Data Columns",
                  "ResultPath": "$.LambdaTaskResult",
                  "ResultSelector": {
                    "SensitiveDataColumns.$": "$.Payload"
                  }
                },
                "Validate if the Dataset Contains Sensitive Data Columns": {
                  "Type": "Choice",
                  "Choices": [
                    {
                      "Variable": "$.LambdaTaskResult.SensitiveDataColumns",
                      "StringEquals": "No Sensitive Data columns found.",
                      "Next": "CopyObject"
                    }
                  ],
                  "Default": "Create Glue DataBrew Dataset"
                },
                "CopyObject": {
                  "Type": "Task",
                  "Parameters": {
                    "ServerSideEncryption": "AES256",
                    "CopySource.$": "States.Format('{}/{}',$.bucket.name,$.object.key)",
                    "Bucket": "${GlueDataBrewOutputBucketName}",
                    "Key.$": "$.object.key"
                  },
                  "InputPath": "$.detail",
                  "Next": "No Sensitive Data Data is Found",
                  "Resource": "arn:aws:states:::aws-sdk:s3:copyObject"
                },
                "No Sensitive Data Data is Found": {
                  "Type": "Succeed"
                },
                "Create Glue DataBrew Dataset": {
                  "Type": "Task",
                  "Parameters": {
                    "Input": {
                      "S3InputDefinition": {
                        "Bucket.$": "$.bucket.name",
                        "Key.$": "$.object.key"
                      }
                    },
                    "FormatOptions": {
                      "Csv": {
                        "Delimiter": ";"
                      }
                    },
                    "Name.$": "$.object.key"
                  },
                  "Resource": "arn:aws:states:::aws-sdk:databrew:createDataset",
                  "Next": "Create Glue DataBrew Sensitive Data Data Encryption Recipe",
                  "InputPath": "$.detail",
                  "ResultPath": "$.DataBrewDatasetResult"
                },
                "Create Glue DataBrew Sensitive Data Data Encryption Recipe": {
                  "Type": "Task",
                  "Parameters": {
                    "Name.$": "States.Format('{}-SensitiveData-Encryption-Recipe',$.DataBrewDatasetResult.Name)",
                    "Steps": [
                      {
                        "Action": {
                          "Operation": "CRYPTOGRAPHIC_HASH",
                          "Parameters": {
                            "secretId": "${GlueDataBrewSensitiveDataTaskSecretArn}",
                            "sourceColumns.$": "$.LambdaTaskResult.SensitiveDataColumns"
                          }
                        }
                      }
                    ]
                  },
                  "Resource": "arn:aws:states:::aws-sdk:databrew:createRecipe",
                  "Next": "Create Glue DataBrew Project",
                  "ResultPath": "$.Recipe"
                },
                "Create Glue DataBrew Project": {
                  "Type": "Task",
                  "Next": "Create Glue DataBrew Recipe Job",
                  "Parameters": {
                    "DatasetName.$": "$.DataBrewDatasetResult.Name",
                    "Name.$": "States.Format('{}-SensitiveData-Project',$.DataBrewDatasetResult.Name)",
                    "RecipeName.$": "$.Recipe.Name",
                    "RoleArn": "${RoleGlueDataBrewSensitiveDataTask.Arn}"
                  },
                  "Resource": "arn:aws:states:::aws-sdk:databrew:createProject",
                  "ResultPath": "$.Project"
                },
                "Create Glue DataBrew Recipe Job": {
                  "Type": "Task",
                  "Parameters": {
                    "ProjectName.$": "$.Project.Name",
                    "Outputs": [
                      {
                        "Location": {
                          "Bucket": "${GlueDataBrewOutputBucketName}",
                          "Key.$": "$.detail.object.key"
                        },
                        "Overwrite": true
                      }
                    ],
                    "Name.$": "States.Format('{}-SensitiveData-Encryption-Job',$.DataBrewDatasetResult.Name)",
                    "RoleArn": "${RoleGlueDataBrewSensitiveDataTask.Arn}"
                  },
                  "Resource": "arn:aws:states:::aws-sdk:databrew:createRecipeJob",
                  "Next": "Start Glue DataBrew Recipe Job"
                },
                "Start Glue DataBrew Recipe Job": {
                  "Type": "Task",
                  "Resource": "arn:aws:states:::databrew:startJobRun.sync",
                  "Parameters": {
                    "Name.$": "$.Name"
                  },
                  "Next": "Successfully Encryption Sensitive Data Data"
                },
                "Successfully Encryption Sensitive Data Data": {
                  "Type": "Succeed"
                }
              }
            }
          - {GlueDataBrewOutputBucketName: !Ref 'BucketGlueDataBrewSensitiveDataDataOutput', GlueDataBrewSensitiveDataTaskSecretArn: !Ref 'SecretGlueDataBrewSensitiveDataTask'}
      RoleArn: !GetAtt 'RoleStepFunctionsSensitiveDataTask.Arn'

  #Custom resource to create Glue Job code file
  GlueJobCodeCustomResource:
    Type: "Custom::GlueJobCode"
    Properties:
      ServiceToken: !GetAtt GlueJobCodeFunction.Arn
      Bucket: !Ref BucketGlueJob
      StackName_: !Ref AWS::StackName

  #Function to create Glue Job code file
  GlueJobCodeFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        ZipFile: 
          !Sub
            - |
              import random
              import string
              import cfnresponse
              import boto3
              import logging
              
              logger = logging.getLogger()
              logger.setLevel(logging.INFO)
              
              def lambda_handler(event, context):
                logger.info(event)
                bucket = event['ResourceProperties']['Bucket']
                stack = event['ResourceProperties']['StackName_']
                
                s3 = boto3.resource('s3')

                if event['RequestType'] == 'Delete':
                  
                  s3.Object(bucket,f'{stack}-GlueDetectSensitiveDataJob.py').delete()
                  
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
                  return
                
                if event['RequestType'] == 'Create':
                  
                  code = """import sys
              from awsglue.transforms import *
              from awsglue.utils import getResolvedOptions
              from pyspark.context import SparkContext
              from awsglue.context import GlueContext
              from awsglue.job import Job
              from awsglueml.transforms import EntityDetector
              from pyspark.sql.types import MapType, StringType, StructType, StructField
              from awsglue.dynamicframe import DynamicFrame

              args = getResolvedOptions(sys.argv, ["JOB_NAME","RANDOM","BUCKET_SOURCE","KEY_SOURCE","BUCKET_DEST"])

              sc = SparkContext()
              glueContext = GlueContext(sc)
              spark = glueContext.spark_session
              job = Job(glueContext)
              job.init(args["JOB_NAME"], args)

              source = f's3://{args["BUCKET_SOURCE"]}/{args["KEY_SOURCE"]}'

              # Script generated for node Amazon S3
              AmazonS3_node1656699502100 = glueContext.create_dynamic_frame.from_options(
                  format_options={"withHeader": True, "separator": ";", "optimizePerformance": False},
                  connection_type="s3",
                  format="csv",
                  connection_options={"paths": [source]},
                  transformation_ctx="AmazonS3_node1656699502100",
              )

              # Script generated for node Detect SensitiveData
              entity_detector = EntityDetector()
              classified_map = entity_detector.classify_columns(
                  AmazonS3_node1656699502100, ["${1CustomSensitiveDataName}", "${2CustomSensitiveDataName}", "${3CustomSensitiveDataName}", "${5CustomSensitiveDataName}", "${4CustomSensitiveDataName}"], 0.1, 0.5
              )
              items = classified_map.items()
              schema = StructType(
                  [
                      StructField("columnName", StringType(), True),
                      StructField(
                          "entityTypes", StructType([StructField("entityType", StringType(), True)])
                      ),
                  ]
              )
              data_frame = spark.createDataFrame(data=items, schema=schema)
              DetectSensitiveData_node1657029151097 = DynamicFrame.fromDF(data_frame, glueContext, "df_for_sensitivedata")

              # Script generated for node Amazon S3
              AmazonS3_node1657029218467 = glueContext.write_dynamic_frame.from_options(
                  frame=DetectSensitiveData_node1657029151097,
                  connection_type="s3",
                  format="json",
                  connection_options={
                      "path": "s3://"+ args["BUCKET_DEST"] + "/"+ args["RANDOM"] + "/",
                      "partitionKeys": [],
                  },
                  transformation_ctx="AmazonS3_node1657029218467",
              )

              job.commit()"""

                  s3.Object(bucket,f'{stack}-GlueDetectSensitiveDataJob.py').put(Body=code)
                  
                  responseData = {}
                  
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
            - {1CustomSensitiveDataName: !Ref '1CustomSensitiveDataName',
               2CustomSensitiveDataName: !Ref '2CustomSensitiveDataName',
               3CustomSensitiveDataName: !Ref '3CustomSensitiveDataName',
               4CustomSensitiveDataName: !Ref '4CustomSensitiveDataName',
               5CustomSensitiveDataName: !Ref '5CustomSensitiveDataName'
              }
      Handler: 'index.lambda_handler'
      Role: !GetAtt 'RoleLambdaGlueJobCode.Arn'
      Runtime: 'python3.9'

  #Glue jobs
  GlueJobSensitiveDatadetection:
    Type: 'AWS::Glue::Job'
    Properties:
      Command:
        Name:  glueetl
        ScriptLocation:
          !Sub "s3://${BucketGlueJob}/${AWS::StackName}-GlueDetectSensitiveDataJob.py"
      #DefaultArguments:
      #  "--job-bookmark-option": "job-bookmark-enable"
      GlueVersion: '3.0'
      MaxRetries: 1
      MaxCapacity: 2
      ExecutionProperty:
        MaxConcurrentRuns: 10
      Name: !Sub "${AWS::StackName}-GlueDetectSensitiveDataJob"
      Role: !Ref GlueJobRole

  #Glue Sensitive data detection Custom Resource
  GlueSensitiveDataDetectionCustomResource:
    Type: "Custom::GlueCustomEntityType"
    Properties:
      ServiceToken: !GetAtt GlueSensitiveDataDetectionFunction.Arn

  #Glue Sensitive data detection Function
  GlueSensitiveDataDetectionFunction:
    Type: "AWS::Lambda::Function"
    Properties:
      Code:
        ZipFile: 
          !Sub
            - |
              import random
              import string
              import cfnresponse
              import sys
              import logging
              
              from pip._internal import main

              main(['install', '-I', '-q', 'boto3', '--target', '/tmp/', '--no-cache-dir', '--disable-pip-version-check'])
              sys.path.insert(0,'/tmp/')

              import boto3
              from botocore.exceptions import ClientError

              logging.getLogger().setLevel(logging.DEBUG)
              
              def lambda_handler(event, context):
                logging.getLogger().setLevel(logging.DEBUG)
                print(boto3.__version__)
                if event['RequestType'] == 'Delete':
                  client = boto3.client('glue')

                  response = client.delete_custom_entity_type(Name='${4CustomSensitiveDataName}')
                  response = client.delete_custom_entity_type(Name='${5CustomSensitiveDataName}')
                  response = client.delete_custom_entity_type(Name='${3CustomSensitiveDataName}')
                  response = client.delete_custom_entity_type(Name='${2CustomSensitiveDataName}')
                  response = client.delete_custom_entity_type(Name='${1CustomSensitiveDataName}')
                  
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, {})
                  return
                
                if event['RequestType'] == 'Create':
                  client = boto3.client('glue')

                  response_4 = client.create_custom_entity_type(Name='${4CustomSensitiveDataName}', RegexString='${4CustomSensitiveDataValue}')
                  response_5 = client.create_custom_entity_type(Name='${5CustomSensitiveDataName}', RegexString='${5CustomSensitiveDataValue}')
                  response_3 = client.create_custom_entity_type(Name='${3CustomSensitiveDataName}', RegexString='${3CustomSensitiveDataValue}')
                  response_2 = client.create_custom_entity_type(Name='${2CustomSensitiveDataName}', RegexString='${2CustomSensitiveDataValue}')
                  response_1 = client.create_custom_entity_type(Name='${1CustomSensitiveDataName}', RegexString='${1CustomSensitiveDataValue}')
                  
                  responseData = {}
                  cfnresponse.send(event, context, cfnresponse.SUCCESS, responseData)
            - {1CustomSensitiveDataName: !Ref '1CustomSensitiveDataName', 1CustomSensitiveDataValue: !Ref '1CustomSensitiveDataValue',
               2CustomSensitiveDataName: !Ref '2CustomSensitiveDataName', 2CustomSensitiveDataValue: !Ref '2CustomSensitiveDataValue',
               3CustomSensitiveDataName: !Ref '3CustomSensitiveDataName', 3CustomSensitiveDataValue: !Ref '3CustomSensitiveDataValue',
               4CustomSensitiveDataName: !Ref '4CustomSensitiveDataName', 4CustomSensitiveDataValue: !Ref '4CustomSensitiveDataValue',
               5CustomSensitiveDataName: !Ref '5CustomSensitiveDataName', 5CustomSensitiveDataValue: !Ref '5CustomSensitiveDataValue'
              }                                      
      Handler: 'index.lambda_handler'
      Role: !GetAtt 'RoleLambdaGlueDataBrewProfileReader.Arn'
      Runtime: 'python3.9'

  # Lambda functions
  FunctionGlueDataBrewProfileReader:
    Type: 'AWS::Lambda::Function'
    Properties:
      Code:
        ZipFile: |
          import json
          import boto3
          import os

          def lambda_handler(event, context):
            s3Bucket = event["bucket_dest"]
            s3Path =  event["path"]
            
            print(f'bucket: {s3Bucket} ; path: {s3Path}')
            conn = boto3.client('s3')
            s3resource = boto3.resource('s3')
            
            SensitiveDataColumnsList = []
            for key in conn.list_objects_v2(Bucket=s3Bucket, Prefix=s3Path).get("Contents"):
                #print(key['Key'])
                if key['Size'] > 0:
                  s3ObjKey = key['Key']
                  glueJobResultFileIterator = s3resource.Object(s3Bucket, s3ObjKey).get()['Body'].iter_lines()
                  for line in glueJobResultFileIterator:
                    #print(line.decode("utf-8"))
                    glueJobResult = json.loads(line.decode("utf-8"))
                    print(glueJobResult["columnName"])
                    SensitiveDataColumnsList.append(glueJobResult["columnName"])
                    
            if SensitiveDataColumnsList == []:
              return 'No Sensitive Data columns found.'
            else:
              return SensitiveDataColumnsList
      Handler: 'index.lambda_handler'
      Role: !GetAtt 'RoleLambdaGlueDataBrewProfileReader.Arn'
      Runtime: 'python3.9'
      Timeout: 10

  # S3 Buckets
  BucketGlueJob:
    Type: AWS::S3::Bucket
    Properties:
      BucketName:
        !Sub
          - 'demo-glue-encryption-sensitivedata-code-${RandomGUID}'
          - {RandomGUID: !Select [0, !Split ["-", !Select [2, !Split ["/", !Ref AWS::StackId]]]]}
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
  BucketGlueDataBrewSensitiveDataDataInput:
    Type: AWS::S3::Bucket
    Properties:
      BucketName:
        !Sub
          - 'demo-glue-encryption-sensitivedata-data-input-${RandomGUID}'
          - {RandomGUID: !Select [0, !Split ["-", !Select [2, !Split ["/", !Ref AWS::StackId]]]]}
      NotificationConfiguration:
        EventBridgeConfiguration:
          EventBridgeEnabled: true
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256
  BucketGlueDataBrewSensitiveDataDataOutput:
    Type: AWS::S3::Bucket
    Properties:
      BucketName:
        !Sub
          - 'demo-glue-encryption-sensitivedata-data-output-${RandomGUID}'
          - {RandomGUID: !Select [0, !Split ["-", !Select [2, !Split ["/", !Ref AWS::StackId]]]]}
      PublicAccessBlockConfiguration:
        BlockPublicAcls: true
        BlockPublicPolicy: true
        IgnorePublicAcls: true
        RestrictPublicBuckets: true
      BucketEncryption:
        ServerSideEncryptionConfiguration:
          - ServerSideEncryptionByDefault:
              SSEAlgorithm: AES256

  # EventBridge Rule
  EventBridgeRuleNewDataArrival:
    Type: 'AWS::Events::Rule'
    Properties:
      Description: Listen to object creation and update events inside the S3 bucket for data input.
      EventBusName: default
      State: ENABLED
      EventPattern:
        source:
          - aws.s3
        detail-type:
          - Object Created
        detail:
          bucket:
            name:
            - !Ref 'BucketGlueDataBrewSensitiveDataDataInput'
      Targets:
        - Arn: !GetAtt 'StateMachineSensitiveDataTask.Arn'
          Id: NewDataArrivalForSensitiveDataTask
          RoleArn: !GetAtt 'RoleEventBridgeSensitiveDataTask.Arn'

  # Secrets Manager Secret
  SecretGlueDataBrewSensitiveDataTask:
    Type: 'AWS::SecretsManager::Secret'
    Properties:
      Name: !Sub "${AWS::StackName}-GlueDataBrewSensitiveDataTaskSecret"
      Description: "Dynamically generate a secret for Glue DataBrew."
      SecretString:
        Fn::Base64:
          !Ref SecretString

  # IAM roles
  RoleLambdaGlueJobCode:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: 'lambda.amazonaws.com'
          Action: 'sts:AssumeRole'
      Policies:
      - PolicyName: LambdaS3BucketsAccess
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action:
            - s3:GetObject
            - s3:PutObject
            - s3:DeleteObject
            - s3:ListBucket
            - s3:PutObjectAcl
            Resource:
            - !GetAtt 'BucketGlueJob.Arn'
            - !Join
                - ''
                - - !GetAtt 'BucketGlueJob.Arn'
                  - /*
      ManagedPolicyArns:
      - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole' 
  GlueJobRole:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: 'glue.amazonaws.com'
          Action: 'sts:AssumeRole'
      Policies:
      - PolicyName: GlueS3BucketsAccess
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action:
            - s3:GetObject
            - s3:PutObject
            - s3:DeleteObject
            - s3:ListBucket
            - s3:PutObjectAcl
            Resource:
            - !GetAtt 'BucketGlueJob.Arn'
            - !Join
                - ''
                - - !GetAtt 'BucketGlueJob.Arn'
                  - !Sub "/${AWS::StackName}-GlueDetectSensitiveDataJob.py"
            
            - !GetAtt 'BucketGlueDataBrewSensitiveDataDataInput.Arn'
            - !Join
                - ''
                - - !GetAtt 'BucketGlueDataBrewSensitiveDataDataInput.Arn'
                  - /*   
            - !GetAtt 'BucketGlueDataBrewSensitiveDataDataOutput.Arn'
            - !Join
                - ''
                - - !GetAtt 'BucketGlueDataBrewSensitiveDataDataOutput.Arn'
                  - /*      
      ManagedPolicyArns:
      - 'arn:aws:iam::aws:policy/service-role/AWSGlueServiceRole'
  RoleStepFunctionsSensitiveDataTask:
    Type: 'AWS::IAM::Role'
    DependsOn: GlueJobSensitiveDatadetection
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: 'states.amazonaws.com'
          Action: 'sts:AssumeRole'
      Policies:
      - PolicyName: StepFunctionsS3BucketAccess
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action:
            - s3:GetObject
            - s3:PutObject
            - s3:DeleteObject
            - s3:PutObjectAcl
            Resource:
            - !Join
                - ''
                - - !GetAtt 'BucketGlueDataBrewSensitiveDataDataInput.Arn'
                  - /*
            - !Join
                - ''
                - - !GetAtt 'BucketGlueDataBrewSensitiveDataDataOutput.Arn'
                  - /*
      - PolicyName: InvokeFunctionGlueDataBrewProfileReader
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action: 'lambda:InvokeFunction'
            Resource:
            - !GetAtt 'FunctionGlueDataBrewProfileReader.Arn'
      - PolicyName: RunGlueJobSensitiveDataDetection
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action: 
            - 'glue:StartJobRun'
            - 'glue:GetJobRun'
            Resource: 
            - !Sub arn:${AWS::Partition}:glue:${AWS::Region}:${AWS::AccountId}:job/${GlueJobSensitiveDatadetection}
      ManagedPolicyArns:
      - 'arn:aws:iam::aws:policy/AwsGlueDataBrewFullAccessPolicy'
  RoleGlueDataBrewSensitiveDataTask:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: 'databrew.amazonaws.com'
          Action: 'sts:AssumeRole'
      Policies:
      - PolicyName: DataBrewS3BucketsAccess
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action:
            - s3:GetObject
            - s3:PutObject
            - s3:DeleteObject
            - s3:ListBucket
            - s3:PutObjectAcl
            Resource:
            - !GetAtt 'BucketGlueDataBrewSensitiveDataDataInput.Arn'
            - !Join
                - ''
                - - !GetAtt 'BucketGlueDataBrewSensitiveDataDataInput.Arn'
                  - /*   
            - !GetAtt 'BucketGlueDataBrewSensitiveDataDataOutput.Arn'
            - !Join
                - ''
                - - !GetAtt 'BucketGlueDataBrewSensitiveDataDataOutput.Arn'
                  - /*
      - PolicyName: GetGlueDataBrewSensitiveDataTaskSecret
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action:
            - 'secretsmanager:GetResourcePolicy'
            - 'secretsmanager:GetSecretValue'
            - 'secretsmanager:DescribeSecret'
            - 'secretsmanager:ListSecretVersionIds'
            Resource:
            - !Ref 'SecretGlueDataBrewSensitiveDataTask'
          - Effect: Allow
            Action: 'secretsmanager:ListSecrets'
            Resource: '*'
      ManagedPolicyArns:
      - 'arn:aws:iam::aws:policy/service-role/AWSGlueDataBrewServiceRole'
  RoleLambdaGlueDataBrewProfileReader:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: 'lambda.amazonaws.com'
          Action: 'sts:AssumeRole'
      Policies:
      - PolicyName: GlueCreateDeleteCustomEntityType
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action:
            - 'glue:CreateCustomEntityType'
            - 'glue:DeleteCustomEntityType'
            Resource: '*'
      - PolicyName: DataBrewS3BucketsAccess
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action:
            - 's3:GetObject'
            - 's3:ListBucket'
            Resource:
            - !GetAtt 'BucketGlueDataBrewSensitiveDataDataOutput.Arn'
            - !Join
                - ''
                - - !GetAtt 'BucketGlueDataBrewSensitiveDataDataOutput.Arn'
                  - /*    
      ManagedPolicyArns:
      - 'arn:aws:iam::aws:policy/service-role/AWSLambdaBasicExecutionRole'
  RoleEventBridgeSensitiveDataTask:
    Type: 'AWS::IAM::Role'
    Properties:
      AssumeRolePolicyDocument:
        Version: '2012-10-17'
        Statement:
        - Effect: Allow
          Principal:
            Service: 'events.amazonaws.com'
          Action: 'sts:AssumeRole'
      Policies:
      - PolicyName: StepFunctionsStateMachine-SensitiveData-Task-Trigger
        PolicyDocument:
          Statement:
          - Effect: Allow
            Action:
              - 'states:StartExecution'
            Resource:
              - !GetAtt 'StateMachineSensitiveDataTask.Arn'

Outputs:
  AmazonS3BucketForDataInput:
    Value: !Sub https://s3.console.aws.amazon.com/s3/buckets/${BucketGlueDataBrewSensitiveDataDataInput}?region=${AWS::Region}
  AmazonS3BucketForDataOuput:
    Value: !Sub https://s3.console.aws.amazon.com/s3/buckets/${BucketGlueDataBrewSensitiveDataDataOutput}?region=${AWS::Region}
  AWSStepFunctionsStateMachine:
    Value: !Sub https://console.aws.amazon.com/states/home?region=${AWS::Region}#/statemachines/view/${StateMachineSensitiveDataTask}
  